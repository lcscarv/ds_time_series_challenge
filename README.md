# Desafio Forma√ß√£o Data Science - An√°lise de S√©ries Temporais

Esse projeto √© referente ao desafio da forma√ß√£o em Data Science do programa Lighthouse da turma de 2023.  
Nesse desafio foi proposto a an√°lise de s√©ries temporais dos dados obtidos do [International Monetary Fund]([International Monetary Fund - IMF](https://www.imf.org/en/Home)) da varia√ß√£o do √≠ndice GDP de diversos pa√≠ses, indo da an√°lise explorat√≥ria de dados (EDA) ao forecasting dos anos de 2024 a 2028, comparando com dados de previs√£o feitos anteriormente pelo Statistica. 

Nesse projeto foram utilizados o Jupyter Notebook para as an√°lises, experimenta√ß√£o e relat√≥rio, que pode ser consultado na pasta `notebooks`,  e o Kedro para a constru√ß√£o do Pipeline do pr√©-processamento dos dados √† previs√£o, cujos resultados podem ser encontrados na pasta `data/08_reporting`. 
Os resultados est√£o no formato de planilha Excel `.xlsx`, organizados da mesma maneira que os dados originais, com a diferen√ßa dos dados faltantes preenchidos e previs√µes dos anos de 2024 a 2028.

## üöÄ Come√ßando

Essas instru√ß√µes permitir√£o que voc√™ obtenha uma c√≥pia do projeto em opera√ß√£o na sua m√°quina local para fins de desenvolvimento e teste.
Para este projeto, fa√ßa uma c√≥pia em sua m√°quina local utilizando o comando

`git clone https://github.com/lcscarv/ds_time_series_challenge.git`

### üìã Pr√©-requisitos

√â preciso criar um¬†[ambiente virtual](https://pythonacademy.com.br/blog/python-e-virtualenv-como-programar-em-ambientes-virtuais)¬†na pasta home do projeto (caso voc√™ ainda n√£o o tenha feito).

- `python3 -m venv venv`¬†ou
    
- `py -3.8 -m venv venv`¬†para Bash no Windows.
    

Caso voc√™ tamb√©m tenha instalada uma vers√£o posterior ao python 3.8,¬†**prefira usar a vers√£o 3.8**. A¬†**vers√£o do Python**¬†utilizada neste projeto √© a¬†**3.8.10**.

Al√©m disso, o¬†**virtual environment deve ser ativado toda vez que voc√™ abrir o projeto**¬†atrav√©s do comando:

- `source venv/bin/activate`¬†no Linux ou
    
- `source venv/Scripts/activate`¬†em bash no Windows, ou ainda
    
- `.\venv\Scripts\activate.ps1`¬†no Windows PowerShell
    

Garanta que voc√™ est√° na pasta onde o ambiente virtual foi criado. Se ele for ativado corretamente, o terminal ter√° uma flag apontando¬†**_(venv)_**¬†na frente do nome do usu√°rio antes de cada comando. Para desativar o ambiente virtual, basta rodar:

- `deactivate`.
### üîß Instala√ß√£o

O pr√≥ximo passo √© instalar as bibliotecas listadas no arquivo¬†**requirements.txt**. Isso pode ser executado atrav√©s do¬†[pip](https://pypi.org/project/pip/):

- `pip install -r src/requirements.txt`¬†ou
    
- `python -m pip install -r scr/requirements.txt`¬†para alguns casos em que o comando anterior n√£o funciona.
    

	Para conferir se todas as bibliotecas foram instaladas corretamente, utilize¬†`pip list`¬†ou `pip freeze` e valide as bibliotecas e suas respectivas vers√µes listadas.

## ‚öôÔ∏è Executando o projeto

Para a execu√ß√£o do pipeline, primeiro √© preciso rodar os arquivos `groups.py` e `best_models.py`. Esses arquivos podem ser acessados da seguinte maneira:
- Estando na pasta central do projeto `time_series_indicium`, acesse a pasta `pipelines`
`cd src/time_series_indicium/pipelines`
- Dentro da pasta, primeiro acesse a pasta `feature_engineering` para rodar o arquivo `groups.py`.
`cd feature_engineering`
`python -m groups`
- Retornando √† pasta pipelines, acesse a pasta `training` para rodar o arquivo `best_models.py`
`cd ..`
`cd training`
`python -m best_models`
- Com esses passos finalizados, retorne √† pasta central do projeto para rodar o pipeline.
`kedro run`

Certifique-se de estar na pasta `time_series_indicium` para rodar o comando. Isso ir√° rodar o projeto de ponta a ponta, resultando em arquivos `.csv` intermedi√°rios caso queira consultar as etapas de transforma√ß√£o dos dados (pr√©-processamento -> imputa√ß√£o -> convers√£o para dataset de formato longo -> previs√µes -> tratamento de formato longo para formato wide -> formata√ß√£o -> dataset final em planilha Excel.)

## üõ†Ô∏è Constru√≠do com

* [Kedro](https://docs.kedro.org/en/stable/) - O framework usado para constru√ß√£o de pipeline de Data Science
* [Jupyter Notebook](https://docs.jupyter.org/en/latest/) - Usado para experimenta√ß√£o e relat√≥rio
* [Miceforest: Multiple Imputation with LightGBM in Python](https://github.com/AnotherSamWilson/miceforest)- Usada para imputa√ß√£o de valores faltantes
* [Statsforecast](https://github.com/Nixtla/statsforecast) - Usando para treinamento de modelos e previs√£o das s√©ries temporais
* [Pandas](https://pandas.pydata.org/docs/) - Usado para consulta e tratamento de dados
* [Numpy](https://numpy.org/doc/stable/ ) - Usado para opera√ß√µes nos dados
* [Seaborn](https://seaborn.pydata.org/) - Usado para visualiza√ß√µes no Notebook.


## ‚úíÔ∏è Autor


* **Lucas de Almeida Sabino Carvalho** - *Data Science Apprentice*  

## üéÅ Agradecimentos

* Expresso minha gratid√£o a todos que tive a liberdade de consultar para tirar d√∫vidas sobre esse projeto, em especial ao Time 42 e seus membros que deram todo o suporte a seus integrantes lighthousers para que pudessem concluir este desafio.
